\documentclass[11pt]{amsart}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, total={6in,8in}, portrait, margin=1in]{geometry}
\usepackage{amssymb}

%Add any packages you need here
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{float}
\usepackage{natbib}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage[misc]{ifsym}
\usepackage{indentfirst} 
\usepackage{amsthm}
\usepackage{appendix}

%Any functions you wanna define, pop 'em here
\newtheorem{theorem}{Theorem}[section]
\newtheorem{remark}[theorem]{Remark}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}

\title[Improving DLS]{Improving Duckworth-Lewis: Statistical Methods for Revising Score Targets in Limited Overs Cricket}
\author{Matthew Knowles}
\date{Autumn Term 2021}

\begin{document}

\maketitle

\section{Prelude: The Game of Cricket}
Before we can discuss any maths, it is important to discuss the motivating playground for this exploration in data science: the game of cricket.
Cricket takes a few forms, but the version that we care most about in this project is ``One Day International'' (ODI) cricket. ODIs are a form of 
\textit{limited overs cricket}. Meaning each team gets a set number of \textit{overs}\footnote{An over consits of 6 individual balls, bowled by the same person from one end of the pitch.} in which to bat. We have two teams of 11 players, one team ``fields''
while the other bats. The batting team bat in pairs, but if one of the pair gets ``out" (which can be achieved in many ways), then the next batter takes their place.
This goes on until all 50 overs are completed, or the batting team run out of batters. \\

Sometimes however, the game is interrupted due to a adverse weather, a medical emergency or another form interrupted. If this happens when the first team is batting,
known as the first innings, then the second innings is reduced to the same number of overs that the first innings had. But if this interruption occurs in the second 
innings, then we have a problem on our hand. Because it is unfair to expect the second team to achieve the same as the first team in less time. 
This is a problem that English statisticians Frank Duckworth and Tony Lewis decided to tackle. Their paper, \cite{duckworth} outlined a method which became 
adopted by cricket's governing body, the International Cricket Council (ICC) in 1999. \\

Duckworth and Lewis later retired, and the method was updated by Professor Steven Stern in his 2016 paper \cite{stern}. The method needed
updating to account for a new form of limited overs cricket: the T20 format. In T20, each team has an innings lasting 20 overs, rather than 50. The Duckworth-Lewis method as it was known,
was not designed with such a format in mind, and so the updates by Stern aimed to adress this. The method is known today as the Duckworth-Lewis Stern method, or ``DLS'' for short.

\section{Introduction and Aims}
The cricket community has had problems with the DLS for many years, especially in T20 cricket, due to the massively increased scoring rates that the method 
wasn't initially designed to deal with. Nowadays, the use of data in sport in general, and in particular, cricket, has become commonplace. Teams use data in varying
ways to try and give themselves an advantage going into games. The aim of this project is to use match data and train pattern recognition models on it, 
in order to see if using more sophisticated methods leads to more accurate score prediction in ODI cricket. \\

The pattern recognition methods chosen are neural networks, and clustering. Neural Networks were chosen to their reputation for predictions. They're being employed
all over modern society, from predicting stock prices \cite{nnstock}, to diagnosing cancer \cite{nncancer}. This flexibility and power makes neural networks 
a great choice of method for predicting cricket scores. The second method is clustering. The idea behind clustering is that simmilar games will appear close together 
when clustered based on a couple of factors. We can then look at how a game is behaving, and which cluster it is likely to end up in. Clustering is often used 
by online shopping websites, for reccomending customers products based on purchase history \cite{retailClus}. The motivation for using it is similar, except the history
comes in the form of a metric in a cricket game, rather than what products may have been purchased by someone online. \\

The problems with DLS itself will be discussed in slightly more detail later on, but another reason it would be better to find a pattern recognition method for resetting score targets
is that DLS is cumbersome. It produces a big table of values that must be input into an equation depending on the scenario a game is in. If the Nueral Network method 
is found to be more accurate, we just have to feed the current match state into a computer program and we're done. No need for messing around with resource tables and ratios. 


\section{Data}
\subsection{Data Origin and Structure}
The primary source of data for carrying out this project was downloaded from ``cricsheet''\footnote{https://cricsheet.org/}
and stored locally on a private server. In total there are 2167 individual matches of data, each in a JSON format.
These cover matches ranging from the $3^{rd}$ of January, 2004. Up to the $20^{th}$ of July, 2021. \\ 

Each JSON file contains a considerable amount of metadata surrounding the match in question. Along with 
ball-by-ball data for the entire match. We have access to attributes such as the date, where the match was played,
the entire teamsheet for both teams, who the officials were, who won- and by what margin, who won the toss; and many others.

We also have the ball-by-ball data. So for every ball bowled, it gives who were the striking and non-striking batsmen, how many runs
were scored and how. It also details if a wicket was taken that ball, and how.

\subsection{Pre-Processing}
In order to get data in to a usable form, Python scripts were written to read the JSON files and extract features necessary for this project.
These Python scripts output CSV files that can be fed into R for easier statistical analysis. For example, when training the neural network model,
a Python script was built to extract the runs scored in each over for over 1400 games. The labelled CSV data was then used by an R script to 
output a matrix of runrates and corresponding final runs, which was used to train the Neural Network.


\section{Duckworth-Lewis}
We begin by looking at the main equation that is the backbone of the Duckworth-Lewis method.

\begin{equation}
    \label{dleq}
    Z(u,w) = Z_0(w)[1-exp(-b(w)u)]
\end{equation}

In \ref{dleq}, u represents the number of overs the runs are scored in, w is the number of wickets lost, and b(w) is an exponential decay constant.
Due to commercial reasons, the authors were unble to publish some of the mathematical constants that they used. The fact this model follows an exponential decay 
pattern is the key thing. Infact, this is consistent with how runs per wicket evolves. \\

The exponential model we see here gives rise to the first issue. The values for the constants were derived from ODI matches only, which is why this method 
isn't immediately applicable to T20 cricket. But it does capture the idea that as a team looses out on batters and overs, the amount of runs they can realistically score
begins to dwindle. In \cite{dlbayes}, the authors find that a Bayesian approach to this method does a better job of capturing this idea of exponential decay. 


\section{Improving DLS - Statistical Pattern Recognition}

The main aim of this project, as previously mentioned, is to investigate ways of producing more realistic score targets for interruption. The main way we look to 
achieve this is through statistical pattern recognition methods. Below we discuss each of the methods that will be investigated in the main dissertation.

\subsection{Neural Networks}
Neural Networks are a a mathematical object that aims to immitate how neurons work in a brain. We have several layers of nodes. This takes the form of an input layer,
several \textit{hidden} layers, and an ouput layer (which in our case is just a single node). Each node holds a value. In the input layer this is just the input data, and the value of the output layer is the prediction.
Each node in one layer connects to each node in the next layer via a connection, which is characterised by a weight value and a bias value. \\

we store the value of the weights as a matrix, and the biases as a column vector. Let $W^{(1)}$ be the matrix containing the weights of connections from the input layer to the first hidden layer. Further, let
$\textbf{a}^0$ be the column vector of values in the input layer, and $\textbf{b}^1$ the biases between the input layer and first hidden layer. Then the values of the nodes in the second 
layer are given by the matrix equation \ref{act}.

\begin{equation}
    \label{act}
    A^{(1)} = W^{(1)}\textbf{a}^0 + \textbf{b}^1
\end{equation}

The same process is then repeated for the other layers. The actual \textit{learning} of the network comes from an algorithm called ``backpropogation''.
The idea is to minimise an error function that gets its values by comparing the network's output for a sample set of data to the actual value for that data. By changing 
the weights and biases to minimise this function, we obtain a set of weights and biases that give accurate predictions for future datasets. \\

The only issue to be wary of at this point, is that we don't actually have that much data. these models are often trained on millions of data points, but in our case we are naturally 
limited by the number of ODI matches that actually get played. In total we have 1436 datapoints to use in training, which isn't ideal, but it should still work with enough itterations of backpropogation.

Backpropogation is the algorithm used for training neural networks. The idea is to tell the network how badly the guess it has made is by using an error function,

\begin{equation}
    E(X,\theta) = \frac{1}{2N}\sum^N_{i=1}(y_i'-y_i)^2
\end{equation}

where $\theta$ denotes a parameter incorperating the weights and biases, and X is the input vector. The error function makes a comparrison of the predicted value $y'$, and the actual
valye for the X input vector, $y$. The aim of backpropogation is to find the parameter $\theta$ which minimises this function, and as a result
giving the set of weights and biases that provide the best prodictions for an unseen dataset $X'$. 

The ``learning rule'' for updating the weights linking node j in one layer to node i in the previous is given by \ref{learnrule}.

\begin{equation}
    \label{learnrule}
    \Delta w_{ji} = \alpha x_i \delta_j
\end{equation}

Where $\delta_j$ is the sensitivity for a node. Based on the sum of the weights and activations of the connections going into it. The formal definition is
outlined in chapter 6 of \cite{Duda}. In \ref{learnrule}, $\alpha$ is the ``learning rate''. 

\subsection{Clustering}
The next method we plan to look at is that of clustering. We can cluster games based on certain metrics in order to prpedict how as a score will evolve.
The idea is to cluster our samples using the k-means clustering algorithm \cite{Duda} (chapter 10.4.3). This clusters the results 
based on means of the sample data. The $k$ refers to the number of clusters we break the data into. This process works as in the following algorithm. \\

\begin{algorithmic}[1]
    \State $\text{Initialise} \ n,c,\mu_1,\ldots,\mu_c$
    \Repeat
        \State $\text{Classify n samples according to nearest} \ \mu_i$
        \State $\text{Recalculate} \ \mu_i$
    \Until{$\text{No change in} \ \mu_i$}
\end{algorithmic}

\section{Discussion}
After discussing with performance analysysts at Yorkshire, Kent and Somerset county cricket clubs, most of the data used in cricket 
matches for informing performance decision tends to be qualitative rather than qualitative. The field is looking to explore using deeper
mathematical modelling techniques, but the issue comes when presenting the results of these to cricket players, who are naturally not 
familiar with higher level maths, which can make communicating the results and what that means for the team difficult. \\

The main result of the report will come from the comparrison between the two pattern recognition techniques outlined above, and how 
the method which performs better fairs against the current DLS method being used by the International Cricket Council today.  


\bibliography{../Thesis/refs}{}
\bibliographystyle{plain}

\end{document}